{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "pd.options.plotting.backend = \"plotly\"\n",
    "from pyts.decomposition import SingularSpectrumAnalysis\n",
    "import plotly.express as px\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_percentage_error\n",
    "import plotly.express as px\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "import plotly.graph_objs as go\n",
    "from plotly.subplots import make_subplots\n",
    "from scipy import signal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset: Energy consumption\n",
    "These data has been extracted from *RTE* and *MeteoFrance* APIs\n",
    "### Columns : \n",
    "- **Consommation** : Britanny power consumption in MW\n",
    "- **Température (°C)** : External temperature\n",
    "- **Nebulosité totale** : Cloud cover\n",
    "- **Date**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "DATAPATH = \"../Dataset/Consommation_Bretagne.csv\"\n",
    "df = pd.read_csv(DATAPATH)\n",
    "df[\"Date\"] = pd.to_datetime(df[\"Date\"])\n",
    "df = df.set_index(\"Date\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = df.plot()\n",
    "fig.update_layout(width=800, height=600)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ACF/PACF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "import plotly.subplots as sp\n",
    "\n",
    "# Calculate ACF and PACF values\n",
    "acf_values = sm.tsa.acf(df[\"Consommation\"], nlags=24 * 7 * 2)\n",
    "pacf_values = sm.tsa.pacf(df[\"Consommation\"], nlags=24 * 7 * 2)\n",
    "\n",
    "# Create a subplot with two subplots (one for ACF and one for PACF)\n",
    "fig = sp.make_subplots(\n",
    "    rows=1,\n",
    "    cols=2,\n",
    "    subplot_titles=[\n",
    "        \"Autocorrelation Function (ACF)\",\n",
    "        \"Partial Autocorrelation Function (PACF)\",\n",
    "    ],\n",
    ")\n",
    "\n",
    "# Add ACF trace\n",
    "acf_trace = go.Scatter(\n",
    "    x=list(range(len(acf_values))), y=acf_values, mode=\"lines\", name=\"ACF\"\n",
    ")\n",
    "fig.add_trace(acf_trace, row=1, col=1)\n",
    "\n",
    "# Add PACF trace\n",
    "pacf_trace = go.Scatter(\n",
    "    x=list(range(len(pacf_values))), y=pacf_values, mode=\"lines\", name=\"PACF\"\n",
    ")\n",
    "fig.add_trace(pacf_trace, row=1, col=2)\n",
    "\n",
    "# Update layout\n",
    "fig.update_layout(title_text=\"ACF and PACF Plots\", showlegend=True)\n",
    "\n",
    "# Show the figure\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spectral analyses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_series = df[\"Consommation\"].values\n",
    "time = np.arange(len(time_series))\n",
    "\n",
    "# Compute the FFT\n",
    "fft_result = np.fft.fft(time_series)\n",
    "\n",
    "# Calculate Frequencies\n",
    "n = len(time_series)\n",
    "timestep = 1  # Set your time step here (e.g., 1 day, 1 hour)\n",
    "freq = np.fft.fftfreq(n, d=timestep)\n",
    "\n",
    "# Keep only positive frequencies\n",
    "positive_freqs = freq > 0\n",
    "fft_positive = fft_result[positive_freqs]\n",
    "freq_positive = freq[positive_freqs]\n",
    "\n",
    "# Calculate Power Spectral Density for positive frequencies\n",
    "psd_positive = np.abs(fft_positive) ** 2 / n\n",
    "\n",
    "fig = make_subplots(\n",
    "    rows=1, cols=2, subplot_titles=(\"Time Series\", \"Power Spectral Density\")\n",
    ")\n",
    "fig.add_trace(\n",
    "    go.Scatter(x=time, y=time_series, mode=\"lines\", name=\"Time Series\"), row=1, col=1\n",
    ")\n",
    "fig.add_trace(\n",
    "    go.Scatter(x=freq_positive, y=psd_positive, mode=\"lines\", name=\"PSD\"), row=1, col=2\n",
    ")\n",
    "\n",
    "fig.update_layout(\n",
    "    title=\"Time Series and its Power Spectral Density\",\n",
    "    xaxis_title=\"Time\",\n",
    "    xaxis2_title=\"Frequency\",\n",
    "    yaxis_title=\"Amplitude\",\n",
    "    yaxis2_title=\"Power\",\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample time series data\n",
    "time_series = df[\"Consommation\"].values\n",
    "time = np.arange(len(time_series))\n",
    "sampling_rate = 1  # Define the sampling rate of your time series\n",
    "\n",
    "# Define window length (nperseg) and overlap (noverlap)\n",
    "nperseg = 24 * 7 * 4 * 2  # Define the window length as per your analysis requirement\n",
    "noverlap = nperseg - 1  # For a stride of 1\n",
    "\n",
    "# Compute the Spectrogram\n",
    "frequencies, times, spectrogram = signal.spectrogram(\n",
    "    time_series, fs=sampling_rate, nperseg=nperseg, noverlap=noverlap\n",
    ")\n",
    "\n",
    "fig = make_subplots(\n",
    "    rows=1,\n",
    "    cols=2,\n",
    "    subplot_titles=(\"Time Series\", \"Spectrogram\"),\n",
    "    specs=[[{\"type\": \"scatter\"}, {\"type\": \"heatmap\"}]],\n",
    ")\n",
    "fig.add_trace(\n",
    "    go.Scatter(x=time, y=time_series, mode=\"lines\", name=\"Time Series\"), row=1, col=1\n",
    ")\n",
    "fig.add_trace(\n",
    "    go.Heatmap(\n",
    "        x=times,\n",
    "        y=frequencies,\n",
    "        z=10 * np.log10(spectrogram),\n",
    "        colorscale=\"Jet\",\n",
    "        colorbar=dict(title=\"Power dB\", x=0.46),\n",
    "        name=\"Spectrogram\",\n",
    "    ),\n",
    "    row=1,\n",
    "    col=2,\n",
    ")\n",
    "fig.update_layout(\n",
    "    title=\"Time Series and its Spectrogram\",\n",
    "    xaxis_title=\"Time\",\n",
    "    xaxis2_title=\"Time\",\n",
    "    yaxis_title=\"Amplitude\",\n",
    "    yaxis2_title=\"Frequency\",\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calendar informations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Weekday\"] = df.index.weekday\n",
    "df[\"Hour\"] = df.index.hour\n",
    "df[\"Month\"] = df.index.month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weekday_hour_mat = (\n",
    "    df.groupby([\"Weekday\", \"Hour\"], as_index=False)\n",
    "    .mean()[[\"Weekday\", \"Hour\", \"Consommation\"]]\n",
    "    .pivot(index=\"Weekday\", columns=\"Hour\", values=\"Consommation\")\n",
    ")\n",
    "fig = px.imshow(\n",
    "    weekday_hour_mat,\n",
    "    labels=dict(x=\"Hour\", y=\"Weekday\", color=\"Consommation\"),\n",
    "    x=weekday_hour_mat.columns,\n",
    "    y=weekday_hour_mat.index,\n",
    "    color_continuous_scale=\"Viridis\",\n",
    "    title=\"Consumption Heatmap\",\n",
    ")\n",
    "fig.update_layout(width=800, height=600)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "month_weekday_mat = (\n",
    "    df.groupby([\"Weekday\", \"Month\"], as_index=False)\n",
    "    .mean()[[\"Weekday\", \"Month\", \"Consommation\"]]\n",
    "    .pivot(index=\"Weekday\", columns=\"Month\", values=\"Consommation\")\n",
    ")\n",
    "fig = px.imshow(\n",
    "    month_weekday_mat,\n",
    "    labels=dict(x=\"Month\", y=\"Weekday\", color=\"Consommation\"),\n",
    "    x=month_weekday_mat.columns,\n",
    "    y=month_weekday_mat.index,\n",
    "    color_continuous_scale=\"Viridis\",\n",
    "    title=\"Consumption Heatmap\",\n",
    ")\n",
    "fig.update_layout(width=800, height=600)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exogenous features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temperature_weekday_mat = df.copy()\n",
    "temperature_weekday_mat[\"Température (°C)\"] = temperature_weekday_mat[\n",
    "    \"Température (°C)\"\n",
    "].astype(int)\n",
    "fig = temperature_weekday_mat.groupby(\"Température (°C)\").mean()[\"Consommation\"].plot()\n",
    "fig.update_layout(width=800, height=600)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = (\n",
    "    df[[\"Température (°C)\", \"Consommation\"]]\n",
    "    .rolling(24 * 7)\n",
    "    .corr()[[\"Consommation\"]]\n",
    "    .unstack(level=1)[\"Consommation\"][\"Température (°C)\"]\n",
    "    .rolling(24 * 7, step=24 * 7)\n",
    "    .mean()\n",
    "    .plot()\n",
    ")\n",
    "fig.update_layout(width=800, height=600)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decomposition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying seasonal decomposition to the daily resampled data\n",
    "# Decomposition into trend, seasonal, and residual components\n",
    "decomposition = seasonal_decompose(\n",
    "    df[\"Consommation\"].resample(\"D\").sum(), model=\"additive\"\n",
    ")\n",
    "\n",
    "# Extracting the trend, seasonal, and residual components\n",
    "trend = decomposition.trend.dropna()\n",
    "seasonal = decomposition.seasonal.dropna()\n",
    "residual = decomposition.resid.dropna()\n",
    "\n",
    "# Plotting the decomposition components using Plotly\n",
    "fig_decomposed = go.Figure()\n",
    "fig_decomposed.add_trace(go.Scatter(x=trend.index, y=trend, mode=\"lines\", name=\"Trend\"))\n",
    "fig_decomposed.add_trace(\n",
    "    go.Scatter(x=seasonal.index, y=seasonal, mode=\"lines\", name=\"Seasonal\")\n",
    ")\n",
    "fig_decomposed.add_trace(\n",
    "    go.Scatter(x=residual.index, y=residual, mode=\"lines\", name=\"Residual\")\n",
    ")\n",
    "\n",
    "fig_decomposed.update_layout(\n",
    "    title=\"Seasonal Decomposition of Daily Time Series\",\n",
    "    xaxis_title=\"Time\",\n",
    "    yaxis_title=\"Value\",\n",
    "    template=\"plotly_white\",\n",
    ")\n",
    "fig_decomposed.update_layout(width=800, height=600)\n",
    "fig_decomposed.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resample the data to daily frequency, averaging the values of each day\n",
    "daily_data = df.resample(\"D\").mean()\n",
    "\n",
    "# Feature Engineering: Adding calendar features and lagged variables\n",
    "daily_data[\"weekday\"] = daily_data.index.weekday\n",
    "daily_data[\"month\"] = daily_data.index.month\n",
    "\n",
    "# Adding lagged variables for up to 7 days for temperature and consumption\n",
    "for i in range(1, 8):\n",
    "    daily_data[f\"lagged_temp_{i}\"] = daily_data[\"Température (°C)\"].shift(i)\n",
    "    daily_data[f\"lagged_consumption_{i}\"] = daily_data[\"Consommation\"].shift(i)\n",
    "\n",
    "# Drop rows with NaN values resulting from lagged features creation\n",
    "daily_data = daily_data.dropna()\n",
    "\n",
    "# Define the feature set for the model\n",
    "feature_columns = (\n",
    "    [\"Température (°C)\", \"Nebulosité totale\", \"weekday\", \"month\"]\n",
    "    + [f\"lagged_temp_{i}\" for i in range(1, 8)]\n",
    "    + [f\"lagged_consumption_{i}\" for i in range(1, 8)]\n",
    ")\n",
    "X = daily_data[feature_columns]\n",
    "y = daily_data[\"Consommation\"]\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, shuffle=False\n",
    ")\n",
    "\n",
    "# Initialize and train the Random Forest model\n",
    "model = RandomForestRegressor(random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict power consumption on the testing set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Calculate performance metrics\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "mape = mean_absolute_percentage_error(y_test, y_pred)\n",
    "\n",
    "# Prepare Plotly visualizations for the decomposed components\n",
    "fig_original = px.line(daily_data[\"Consommation\"], title=\"Original Power Consumption\")\n",
    "fig_trend = px.line(decomposition.trend, title=\"Trend Component of Power Consumption\")\n",
    "fig_seasonal = px.line(\n",
    "    decomposition.seasonal, title=\"Seasonal Component of Power Consumption\"\n",
    ")\n",
    "fig_residual = px.line(decomposition.resid, title=\"Residuals of Power Consumption\")\n",
    "\n",
    "# Display performance metrics\n",
    "print(f\"RMSE: {rmse}\")\n",
    "print(f\"R^2: {r2}\")\n",
    "print(f\"MAPE: {mape}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "masterdsb-timeseries-paBJOZVR-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
